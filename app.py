import streamlit as st
import pandas as pd
import joblib
import os
from sklearn.ensemble import IsolationForest

st.set_page_config(page_title="Spindle Vibration Anomaly Detection", layout="wide")

st.title("ğŸ› ï¸ Spindle Vibration Anomaly Detection")
st.markdown("Early detection of abnormal vibration patterns in heavy milling machines using AI.")

# Sidebar for CSV upload
st.sidebar.header("ğŸ“‚ Upload Vibration CSV")
uploaded_file = st.sidebar.file_uploader("Choose a CSV file", type="csv")
st.sidebar.markdown("âš ï¸ CSV must contain: `Vibration_X`, `Vibration_Y`, `Vibration_Z`")

# Load data
if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.success("âœ… Custom data uploaded successfully!")
elif os.path.exists("vibration_logs.csv"):
    df = pd.read_csv("vibration_logs.csv")
    st.info("â„¹ï¸ Using default sample data (vibration_logs.csv)")
else:
    st.error("âŒ No data found. Please upload a CSV file.")
    st.stop()

# Prepare features
X = df[['Vibration_X', 'Vibration_Y', 'Vibration_Z']]

# Train or load model
if not os.path.exists("model.pkl"):
    model = IsolationForest(contamination=0.1, random_state=42)
    model.fit(X)
    joblib.dump(model, "model.pkl")
else:
    model = joblib.load("model.pkl")

# Predict anomalies
df['Anomaly'] = model.predict(X)
df['Anomaly'] = df['Anomaly'].map({1: 'âœ… Normal', -1: 'ğŸš¨ Anomaly'})

# Summary metrics
st.subheader("ğŸ“‹ Anomaly Summary")
col1, col2 = st.columns(2)
col1.metric("âœ… Normal", df['Anomaly'].value_counts().get('âœ… Normal', 0))
col2.metric("ğŸš¨ Anomaly", df['Anomaly'].value_counts().get('ğŸš¨ Anomaly', 0))

# Charts
st.subheader("ğŸ“ˆ Vibration Trends")
st.line_chart(df[['Vibration_X', 'Vibration_Y', 'Vibration_Z']])

# Final table
st.subheader("ğŸ“„ Full Dataset with Anomaly Labels")
st.dataframe(df, use_container_width=True)


